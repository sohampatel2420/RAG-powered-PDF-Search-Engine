# ğŸ“„ RAG-powered PDF Search Engine (FAISS + High-Quality Embeddings)

A **high-accuracy, fully free, Retrieval-Augmented Generation (RAG) system** that allows users to:

âœ… Upload any PDF  
âœ… Automatically build a vector index  
âœ… Ask questions in natural language  
âœ… Get **precise answers with page-level citations**  

Built using **FAISS, BGE embeddings, Streamlit, and a local LLM via Ollama** â€” no paid APIs required.

---

## ğŸš€ Key Features

- âœ… **Automatic PDF indexing** (no manual buttons)
- âœ… **High-accuracy semantic search** using **BGE embeddings**
- âœ… **FAISS vector database** for ultra-fast retrieval
- âœ… **Local LLM inference using Ollama** (100% free)
- âœ… **Page-wise citations for every answer**
- âœ… **Clean, minimal Streamlit UI**
- âœ… Fully offline-capable after setup

---

## ğŸ§  Project Architecture (RAG Pipeline)

    PDF Upload
    â†“
    Text Extraction (PyPDF)
    â†“
    Chunking with Overlap
    â†“
    Vector Embeddings (BGE)
    â†“
    FAISS Index
    â†“
    User Query
    â†“
    Semantic Retrieval (Top-K Chunks)
    â†“
    LLM Answer Generation (Ollama)
    â†“
    Final Answer + Citations



---

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|----------|------------|
| UI | Streamlit |
| PDF Processing | PyPDF |
| Embeddings | `BAAI/bge-base-en-v1.5` |
| Vector Database | FAISS |
| LLM | Ollama (LLaMA 3 / Qwen / Phi) |
| Language | Python |

All tools are **open-source and free of cost** âœ…

---

## ğŸ“ Project Structure

    rag-pdf-search/
    â”‚
    â”œâ”€â”€ app.py # Streamlit app
    â”œâ”€â”€ rag_engine.py # RAG logic (PDF, chunks, embeddings, FAISS, LLM)
    â”œâ”€â”€ requirements.txt
    â”‚
    â””â”€â”€ data/
    â””â”€â”€ index/ # Stored FAISS index + metadata



---

## âš™ï¸ Installation & Setup

1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/your-username/rag-pdf-search.git
cd rag-pdf-search


2ï¸âƒ£ Install Python Dependencies

pip install -r requirements.txt


3ï¸âƒ£ Install & Run Ollama (Local LLM)

Download Ollama from:


https://ollama.com


Then pull a free LLM model:

ollama pull llama3.2
ollama serve


4ï¸âƒ£ Run the Application

streamlit run app.py

Open your browser at:

http://localhost:8501


âœ… How It Works (User Flow)

Upload a PDF file

If you do not have PDF file you will use sample PDF file that is located on data/sample/sample_data.pdf

The system automatically builds the FAISS index

Type your question

Click Search

Get:

âœ… AI-generated answer

âœ… Exact page-number citations

âœ… Retrieved context chunks

ğŸ¯ Why This Project is High Accuracy

Uses BGE embeddings (state-of-the-art open-source)

Uses overlapping smart chunking

Uses semantic search instead of keyword matching

Uses retrieval-grounded answer generation

Prevents hallucination by enforcing:

â€œIf the answer is not in the context, say you donâ€™t know.â€

ğŸ“Š Example Use Cases

ğŸ“š Study Notes Search

ğŸ“„ Legal Document Questioning

ğŸ« Research Paper Assistant

ğŸ“˜ Company Policy Search

ğŸ“‘ Technical Documentation QA

ğŸ”’ Privacy & Cost

âœ… No cloud APIs
âœ… No data leaves your system
âœ… No monthly payment
âœ… Works fully offline after setup

ğŸ§ª Future Improvements (Optional)

âœ… Multi-PDF Search

âœ… Re-ranking with Cross-Encoder

âœ… Chat history

âœ… Export answers as PDF

âœ… API version using FastAPI

âœ… OCR support for scanned PDFs

ğŸ‘¨â€ğŸ’» Author

Soham Patel
Machine Learning | Deep Learning | GenAI | Computer Vision